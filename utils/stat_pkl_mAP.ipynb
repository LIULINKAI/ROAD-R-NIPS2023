{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "# 读取.pkl文件\n",
    "# with open(r'../output/val_1/val_1_vitcliplarge-base-yolov8-bestacc/2023-11-02-15-38-30/val_1_vitcliplarge-base-yolov8-bestacc.pkl', 'rb') as f:\n",
    "with open(r'submit-require-task1.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['all_input_labels', 'all_av_action_labels', 'av_action_labels', 'agent_labels', 'action_labels', 'duplex_labels', 'triplet_labels', 'loc_labels', 'old_loc_labels', 'db', 'label_types', 'all_duplex_labels', 'all_triplet_labels', 'all_agent_labels', 'all_loc_labels', 'all_action_labels', 'duplex_childs', 'triplet_childs'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_file = '/data/llk/projects/road-r/road-dataset/road/road_trainval_v1.0.json'\n",
    "f = open(gt_file, \"r\")\n",
    "annojson = json.loads(f.read())\n",
    "f.close()\n",
    "annojson.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_part_of_subsets(split_ids, SUBSETS):\n",
    "    is_it = False\n",
    "    for subset in SUBSETS:\n",
    "        if subset in split_ids:\n",
    "            is_it = True\n",
    "    return is_it\n",
    "task1_labels = [\"2014-07-14-14-49-50_stereo_centre_01\",\"2015-02-03-19-43-11_stereo_centre_04\",\"2015-02-24-12-32-19_stereo_centre_04\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_video_names = annojson[\"db\"].keys()\n",
    "val_1_video_names = []\n",
    "for vname in all_video_names:\n",
    "    if is_part_of_subsets(annojson[\"db\"][vname][\"split_ids\"], [\"val_1\"]) and vname not in task1_labels:\n",
    "        val_1_video_names.append(vname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_video_names = annojson[\"db\"].keys()\n",
    "train_1_video_names = []\n",
    "for vname in all_video_names:\n",
    "    if is_part_of_subsets(annojson[\"db\"][vname][\"split_ids\"], [\"train_1\"]) and vname not in task1_labels:\n",
    "        train_1_video_names.append(vname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ped',\n",
       " 'Car',\n",
       " 'Cyc',\n",
       " 'Mobike',\n",
       " 'SmalVeh',\n",
       " 'MedVeh',\n",
       " 'LarVeh',\n",
       " 'Bus',\n",
       " 'EmVeh',\n",
       " 'TL',\n",
       " 'OthTL']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annojson['all_agent_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:05<00:00,  1.70s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "num_classes = 41\n",
    "all_det_info = [{} for i in range(num_classes)]\n",
    "frame_id = 0\n",
    "action_and_location_conf_thresh = 0.00\n",
    "for video_name in tqdm(val_1_video_names):\n",
    "    for frame_key in sorted(data[video_name].keys(), key=lambda k:int(k.split(\".\")[0])):\n",
    "        curframe_obj = data[video_name][frame_key]\n",
    "        for tube_idx in range(len(curframe_obj)):\n",
    "            x1, y1, x2, y2 = curframe_obj[tube_idx][\"bbox\"]\n",
    "            labels_conf = curframe_obj[tube_idx][\"labels\"]\n",
    "            # if max(labels_conf) < 0.5:\n",
    "            #     continue\n",
    "            for cls_id in range(num_classes):\n",
    "                if frame_id not in all_det_info[cls_id].keys():\n",
    "                    all_det_info[cls_id][frame_id] = []\n",
    "                all_det_info[cls_id][frame_id].append([x1, y1, x2, y2,  0 if cls_id >= 10 and labels_conf[cls_id] < action_and_location_conf_thresh else labels_conf[cls_id]])\n",
    "        for cls_id in range(num_classes):\n",
    "            if frame_id in all_det_info[cls_id].keys():\n",
    "                all_det_info[cls_id][frame_id] = np.array(all_det_info[cls_id][frame_id])\n",
    "        frame_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 10.19it/s]\n"
     ]
    }
   ],
   "source": [
    "frame_id = 0\n",
    "all_gt_info = {}\n",
    "w, h = 1280, 960\n",
    "def update_agent_clsid(agent_id):\n",
    "    agent_name = annojson['all_agent_labels'][agent_id]\n",
    "    if agent_name in annojson['agent_labels']:\n",
    "        agent_id = annojson['agent_labels'].index(agent_name)\n",
    "    else:\n",
    "        return -1\n",
    "    return agent_id\n",
    "    # if agent_id == 4:\n",
    "    #     return -1\n",
    "    # if agent_id > 4:\n",
    "    #     agent_id -= 1\n",
    "    # return agent_id\n",
    "\n",
    "def update_action_clsid(action_id):\n",
    "    action_name = annojson['all_action_labels'][action_id]\n",
    "    if action_name in annojson['action_labels']:\n",
    "        action_id = annojson['action_labels'].index(action_name)\n",
    "    else:\n",
    "        return -1\n",
    "    return action_id + 10\n",
    "\n",
    "def update_location_clsid(location_id):\n",
    "    return location_id + 29\n",
    "\n",
    "for video_name in tqdm(val_1_video_names):\n",
    "    for frame_key in sorted(annojson[\"db\"][video_name][\"frames\"].keys(), key=lambda k:int(k)):\n",
    "        curframe_obj = annojson[\"db\"][video_name][\"frames\"][frame_key]\n",
    "        if frame_id not in all_gt_info.keys():\n",
    "            all_gt_info[frame_id] = []\n",
    "        if \"annos\" in curframe_obj.keys():\n",
    "            if len(curframe_obj[\"annos\"]) > 0:\n",
    "                for tube_k in curframe_obj[\"annos\"].keys():\n",
    "                    tube_item = curframe_obj[\"annos\"][tube_k]\n",
    "                    x1, y1, x2, y2 = tube_item['box']\n",
    "                    x1, y1, x2, y2 = x1*w, y1*h, x2*w, y2*h\n",
    "                    for agent_id in tube_item[\"agent_ids\"]:\n",
    "                        new_agent_id = update_agent_clsid(agent_id)\n",
    "                        if new_agent_id == -1:\n",
    "                            continue\n",
    "                        all_gt_info[frame_id].append([x1, y1, x2, y2, new_agent_id])\n",
    "                    for action_id in tube_item[\"action_ids\"]:\n",
    "                        new_action_id = update_action_clsid(action_id)\n",
    "                        if new_action_id == -1:\n",
    "                            continue\n",
    "                        all_gt_info[frame_id].append([x1, y1, x2, y2, new_action_id])\n",
    "                    for location_id in tube_item[\"loc_ids\"]:\n",
    "                        new_location_id = update_location_clsid(location_id)\n",
    "                        if new_location_id == -1:\n",
    "                            continue\n",
    "                        all_gt_info[frame_id].append([x1, y1, x2, y2, new_location_id])\n",
    "            else:\n",
    "                all_gt_info[frame_id] = []\n",
    "        else:\n",
    "            all_gt_info[frame_id] = []\n",
    "        all_gt_info[frame_id] = np.array(all_gt_info[frame_id])\n",
    "        frame_id += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算mAP的代码 - baseline版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voc_ap(rec, prec, use_07_metric=False):\n",
    "    \"\"\" ap = voc_ap(rec, prec, [use_07_metric])\n",
    "    Compute VOC AP given precision and recall.\n",
    "    If use_07_metric is true, uses the\n",
    "    VOC 07 11 point method (default:False).\n",
    "    \"\"\"\n",
    "    if use_07_metric:\n",
    "        # 11 point metric\n",
    "        ap = 0.\n",
    "        for t in np.arange(0., 1.1, 0.1):\n",
    "            if np.sum(rec >= t) == 0:\n",
    "                p = 0\n",
    "            else:\n",
    "                p = np.max(prec[rec >= t])\n",
    "            ap = ap + p / 11.\n",
    "    else:\n",
    "        # correct AP calculation\n",
    "        # first append sentinel values at the end\n",
    "        mrec = np.concatenate(([0.], rec, [1.]))\n",
    "        mpre = np.concatenate(([0.], prec, [0.]))\n",
    "\n",
    "        # compute the precision envelope\n",
    "        for i in range(mpre.size - 1, 0, -1):\n",
    "            mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "\n",
    "        # to calculate area under PR curve, look for points\n",
    "        # where X axis (recall) changes value\n",
    "        i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "\n",
    "        # and sum (\\Delta recall) * prec\n",
    "        ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap*100\n",
    "\n",
    "def compute_iou(box, cls_gt_boxes):\n",
    "\n",
    "    ious = np.zeros(cls_gt_boxes.shape[0])\n",
    "\n",
    "    for m in range(cls_gt_boxes.shape[0]):\n",
    "        gtbox = cls_gt_boxes[m]\n",
    "\n",
    "        xmin = max(gtbox[0], box[0])\n",
    "        ymin = max(gtbox[1], box[1])\n",
    "        xmax = min(gtbox[2], box[2])\n",
    "        ymax = min(gtbox[3], box[3])\n",
    "        iw = np.maximum(xmax - xmin, 0.)\n",
    "        ih = np.maximum(ymax - ymin, 0.)\n",
    "        if iw > 0 and ih > 0:\n",
    "            intsc = iw*ih\n",
    "        else:\n",
    "            intsc = 0.0\n",
    "        union = (gtbox[2] - gtbox[0]) * (gtbox[3] - gtbox[1]) + \\\n",
    "            (box[2] - box[0]) * (box[3] - box[1]) - intsc\n",
    "        ious[m] = intsc/union\n",
    "\n",
    "    return ious\n",
    "\n",
    "def get_gt_of_cls(gt_boxes, cls):\n",
    "    cls_gt_boxes = []\n",
    "    for i in range(gt_boxes.shape[0]):\n",
    "        if len(gt_boxes.shape) > 1 and int(gt_boxes[i, -1]) == cls:\n",
    "            cls_gt_boxes.append(gt_boxes[i, :-1])\n",
    "    return np.asarray(cls_gt_boxes)\n",
    "\n",
    "def evaluate_detections(gt_boxes, det_boxes, classes=[], iou_thresh=0.5):\n",
    "    ap_strs = []\n",
    "    num_frames = len(gt_boxes)\n",
    "    print('Evaluating for '+ str(num_frames) + ' frames')\n",
    "    ap_all = np.zeros(len(classes), dtype=np.float32)\n",
    "    # loop over each class 'cls'\n",
    "    for cls_ind, class_name in enumerate(tqdm(classes)):\n",
    "        scores = np.zeros(num_frames * 2000)\n",
    "        istp = np.zeros(num_frames * 2000)\n",
    "        det_count = 0\n",
    "        num_postives = 0.0\n",
    "        for nf in range(num_frames):  # loop over each frame 'nf'\n",
    "                # if len(gt_boxes[nf])>0 and len(det_boxes[cls_ind][nf]):\n",
    "            # get frame detections for class cls in nf\n",
    "            if nf in det_boxes[cls_ind].keys():\n",
    "                frame_det_boxes = np.copy(det_boxes[cls_ind][nf])\n",
    "            else:\n",
    "                frame_det_boxes = np.array([])\n",
    "            # get gt boxes for class cls in nf frame\n",
    "            cls_gt_boxes = get_gt_of_cls(np.copy(gt_boxes[nf]), cls_ind)\n",
    "            num_postives += cls_gt_boxes.shape[0]\n",
    "            # check if there are dection for class cls in nf frame\n",
    "            if frame_det_boxes.shape[0] > 0:\n",
    "                # sort in descending order\n",
    "                sorted_ids = np.argsort(-frame_det_boxes[:, -1])\n",
    "                for k in sorted_ids:  # start from best scoring detection of cls to end\n",
    "                    box = frame_det_boxes[k, :-1]  # detection bounfing box\n",
    "                    score = frame_det_boxes[k, -1]  # detection score\n",
    "                    ispositive = False  # set ispostive to false every time\n",
    "                    # we can only find a postive detection\n",
    "                    if cls_gt_boxes.shape[0] > 0:\n",
    "                        # if there is atleast one gt bounding for class cls is there in frame nf\n",
    "                        # compute IOU between remaining gt boxes\n",
    "                        iou = compute_iou(box, cls_gt_boxes)\n",
    "                        # and detection boxes\n",
    "                        # get the max IOU window gt index\n",
    "                        maxid = np.argmax(iou)\n",
    "                        # check is max IOU is greater than detection threshold\n",
    "                        if iou[maxid] >= iou_thresh:\n",
    "                            ispositive = True  # if yes then this is ture positive detection\n",
    "                            # remove assigned gt box\n",
    "                            cls_gt_boxes = np.delete(cls_gt_boxes, maxid, 0)\n",
    "                    # fill score array with score of current detection\n",
    "                    scores[det_count] = score\n",
    "                    if ispositive:\n",
    "                        # set current detection index (det_count)\n",
    "                        istp[det_count] = 1\n",
    "                        #  to 1 if it is true postive example\n",
    "                    det_count += 1\n",
    "        if num_postives < 1:\n",
    "            num_postives = 1\n",
    "        scores = scores[:det_count]\n",
    "        istp = istp[:det_count]\n",
    "        argsort_scores = np.argsort(-scores)  # sort in descending order\n",
    "        istp = istp[argsort_scores]  # reorder istp's on score sorting\n",
    "        fp = np.cumsum(istp == 0)  # get false positives\n",
    "        tp = np.cumsum(istp == 1)  # get  true positives\n",
    "        fp = fp.astype(np.float64)\n",
    "        tp = tp.astype(np.float64)\n",
    "        recall = tp / float(num_postives)  # compute recall\n",
    "        # compute precision\n",
    "        precision = tp / np.maximum(tp + fp, np.finfo(np.float64).eps)\n",
    "        # compute average precision using voc2007 metric\n",
    "        cls_ap = voc_ap(recall, precision)\n",
    "        ap_all[cls_ind] = cls_ap\n",
    "        ap_str = class_name + ' : ' + \\\n",
    "            str(num_postives) + ' : ' + str(det_count) + ' : ' + str(cls_ap)\n",
    "        ap_strs.append(ap_str)\n",
    "\n",
    "    mAP = np.mean(ap_all)\n",
    "    print('mean ap '+ str(mAP))\n",
    "    print(\"agent mAP: \", ap_all[:10].mean())\n",
    "    print(\"action mAP: \", ap_all[10:29].mean())\n",
    "    print(\"location mAP: \", ap_all[29:41].mean())\n",
    "    return mAP, ap_all, ap_strs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_label_names(label_names_file):\n",
    "    f = open(label_names_file, \"r\")\n",
    "    labelnames = json.loads(f.read())\n",
    "    \n",
    "    agent_labels = labelnames[\"agent_names\"]\n",
    "    action_labels = labelnames[\"action_names\"]\n",
    "    loc_labels = labelnames[\"location_names\"]\n",
    "    f.close()\n",
    "    return agent_labels, action_labels, loc_labels\n",
    "label_names_file = \"/data/llk/projects/road-r/yolov8/road-r-2023-yolov8-semi/configs/label_names.json\"\n",
    "agent_labels, action_labels, loc_labels = load_label_names(label_names_file)\n",
    "class_names = []\n",
    "class_names.extend(agent_labels)\n",
    "class_names.extend(action_labels)\n",
    "class_names.extend(loc_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating for 18000 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:17<00:00,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean ap 28.15609\n",
      "agent mAP:  46.568386\n",
      "action mAP:  20.461746\n",
      "location mAP:  24.995216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mAP, ap_all, ap_strs = evaluate_detections(gt_boxes=all_gt_info, det_boxes=all_det_info, classes=class_names, iou_thresh=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ped : 18949.0 : 54816 : 56.92677056431496\n",
      "Car : 11032.0 : 54816 : 64.87879815204938\n",
      "Cyc : 6139.0 : 54816 : 61.1618194800675\n",
      "Mobike : 2121.0 : 54816 : 10.318326550873303\n",
      "MedVeh : 9895.0 : 54816 : 39.1641410228933\n",
      "LarVeh : 633.0 : 54816 : 3.8810643261972677\n",
      "Bus : 1834.0 : 54816 : 80.38612658852958\n",
      "EmVeh : 1 : 54816 : 0.0\n",
      "TL : 7690.0 : 54816 : 72.90587123451755\n",
      "OthTL : 1810.0 : 54816 : 76.06094572219311\n",
      "Red : 6309.0 : 54816 : 61.18039491902191\n",
      "Amber : 381.0 : 54816 : 67.25355374472953\n",
      "Green : 2810.0 : 54816 : 34.638386780834495\n",
      "MovAway : 14699.0 : 54816 : 39.2959294732644\n",
      "MovTow : 13921.0 : 54816 : 44.21291283678131\n",
      "Mov : 1587.0 : 54816 : 23.695880928611853\n",
      "Brake : 1097.0 : 54816 : 12.963362862726935\n",
      "Stop : 16895.0 : 54816 : 33.24517357878363\n",
      "IncatLft : 1884.0 : 54816 : 4.689689573830523\n",
      "IncatRht : 2015.0 : 54816 : 18.578067179741787\n",
      "HazLit : 1000.0 : 54816 : 7.848621053555559\n",
      "TurLft : 772.0 : 54816 : 5.575325177251311\n",
      "TurRht : 704.0 : 54816 : 13.477214158347643\n",
      "Ovtak : 202.0 : 54816 : 0.2057152309247928\n",
      "Wait2X : 819.0 : 54816 : 4.684749290310133\n",
      "XingFmLft : 2102.0 : 54816 : 11.683315149369996\n",
      "XingFmRht : 1360.0 : 54816 : 1.6267940502019713\n",
      "Xing : 337.0 : 54816 : 1.0076783142095769\n",
      "PushObj : 629.0 : 54816 : 2.910437770395463\n",
      "VehLane : 11895.0 : 54816 : 40.41470079203022\n",
      "OutgoLane : 2051.0 : 54816 : 10.673058115400497\n",
      "OutgoCycLane : 1020.0 : 54816 : 6.731169640493266\n",
      "IncomLane : 10912.0 : 54816 : 53.51123718941311\n",
      "IncomCycLane : 627.0 : 54816 : 8.56136041893431\n",
      "Pav : 1952.0 : 54816 : 18.621490870655087\n",
      "LftPav : 8726.0 : 54816 : 54.6023968441572\n",
      "RhtPav : 7092.0 : 54816 : 41.76322354949511\n",
      "Jun : 11783.0 : 54816 : 42.75665749913482\n",
      "xing : 142.0 : 54816 : 21.37515793417589\n",
      "BusStop : 328.0 : 54816 : 0.8989536579105167\n",
      "parking : 66.0 : 54816 : 0.0331903488958424\n"
     ]
    }
   ],
   "source": [
    "f = open(\"./result.txt\", \"w\", encoding=\"utf-8\")\n",
    "for line in ap_strs:\n",
    "    print(line)\n",
    "    line += '\\n'\n",
    "    f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent mAP:  46.568386\n",
      "action mAP:  20.461746\n",
      "location mAP:  24.995216\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28.15609"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"agent mAP: \", ap_all[:10].mean())\n",
    "print(\"action mAP: \", ap_all[10:29].mean())\n",
    "print(\"location mAP: \", ap_all[29:41].mean())\n",
    "mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
